{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "We want $$0 = \\dot{\\hat{\\rho}} = \\mathcal{L}\\hat{\\rho} = -i\\left[\\hat H, \\hat \\rho\\right]+\\sum_j \\frac{\\gamma_j}{2}\\left[2\\hat L_j\\hat\\rho\\hat L_j^\\dagger - \\left\\{\\hat L_j^\\dagger\\hat L_j, \\hat\\rho\\right\\}\\right]$$\n",
    "In terms of probabilities for POVM, it is equavalent to\n",
    "$$0=\\dot p_a = \\sum_b p_b(-i{A_a}^b+{B_a}^b)$$\n",
    "where\n",
    "$${A_a}^b = \\text{tr}\\left(HN^bM_a\\right)-\\text{tr}\\left(N^bHM_a\\right) = \\sum_{r,s,t}\\left(H_{rs}{N^b}_{st}M_{atr}-{N^b}_{rs}H_{st}M_{atr}\\right)$$\n",
    "\\begin{align*}\n",
    "{B_a}^b  &= \\sum_j\\left[\\text{tr}\\left(L_jN^bL_j^\\dagger M_a\\right) -\\frac{1}{2}\\text{tr}\\left(L_j^\\dagger L_j N^b M_a\\right)-\\frac{1}{2}\\text{tr}\\left(N^b L_j^\\dagger L_j M_a\\right)\\right] \\\\\n",
    "&= \\sum_{j, r,s,t,u}L_{jrs}{N^b}_{st}L_{jut}^* M_{aur}-\\frac{1}{2}L_{jsr}^* L_{jst} {N^b}_{tu} M_{aur} - \\frac{1}{2}{N^b}_{rs} L_{jts}^* L_{jtu} M_{aur}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '16'\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import optimize\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# local packages\n",
    "from model import utils\n",
    "from utils.POVM import *\n",
    "from utils.ncon import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pauli Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_x = np.array([[0, 1], [1, 0]], dtype = 'complex128')\n",
    "sigma_y = np.array([[0, -1j], [1j, 0]], dtype = 'complex128')\n",
    "sigma_z = np.array([[1, 0], [0, -1]], dtype = 'complex128')\n",
    "identity = np.array([[1, 0], [0, 1]], dtype = 'complex128')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_latt = 4\n",
    "coup_stren = 2\n",
    "povm_basis = 'Tetra'  # 4Pauli, Tetra, Tetra_pos\n",
    "method = 'direct' # direct, gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate POVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "povm = POVM(POVM = povm_basis, Number_qubits = num_latt)\n",
    "povm.construct_Nframes()\n",
    "Mn = povm.Mn # M_a\n",
    "Ntn = povm.Ntn # N^b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 16, 16)\n",
      "(256, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "print(Mn.shape)\n",
    "print(Ntn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ H = \\frac{V}{4}\\sum_{\\langle j, l\\rangle}\\hat\\sigma_j^z\\hat\\sigma_l^z+\\frac{g}{2}\\sum_j\\hat\\sigma_j^x$$\n",
    "where $\\hat\\sigma_j^\\alpha$ means the Pauli matrix acting on the $j$-th site.\n",
    "$$ \\hat L_j^{(z)} = \\hat\\sigma_j^- = \\frac{1}{2}\\left(\\hat\\sigma_j^x-i\\hat\\sigma_j^y\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tensor product of two matrices (copied over from povm code, \n",
    "# but I didn't reverse the order because later I shall use this function\n",
    "# in a different order.)\n",
    "def tensorproduct(matrix1, matrix2):\n",
    "    dim = matrix1.shape[0] * matrix2.shape[0]\n",
    "    # didn't reverse the order here\n",
    "    return np.tensordot(matrix1, matrix2, axes = 0).swapaxes(1, 2).reshape(dim, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate hamiltonion (rank 2 tensor)\n",
    "def gen_H(num, V, g):\n",
    "    hamiltonion = np.zeros((2**num, 2**num), dtype = 'complex128')\n",
    "    for i in range(num):\n",
    "        term1 = np.ones((1, 1), dtype = 'complex128')\n",
    "        term2 = np.ones((1, 1), dtype = 'complex128')\n",
    "        for j in range(num): \n",
    "            if j == i or j == i + 1 or (i == num - 1 and j == 0): # wallpaper(cyclic) bondary condition\n",
    "                term1 = tensorproduct(term1, sigma_z) # order here not the same as in POVM\n",
    "                #print(i, j)\n",
    "                #print(term1)\n",
    "            else:\n",
    "                term1 = tensorproduct(term1, identity) # order here not the same as in POVM\n",
    "            if j == i:\n",
    "                term2 = tensorproduct(term2, sigma_x) # order here not the same as in POVM\n",
    "            else:\n",
    "                term2 = tensorproduct(term2, identity) # order here not the same as in POVM\n",
    "        term1 = term1 * V / 4\n",
    "        #print(term1)\n",
    "        term2 = term2 * g / 2\n",
    "        hamiltonion += term1 + term2\n",
    "    return hamiltonion\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate L (rank 3 tensor)\n",
    "def gen_L(num):\n",
    "    L_list = []\n",
    "    for i in range(num):\n",
    "        term = np.ones((1, 1), dtype = 'complex128')\n",
    "        for j in range(num):\n",
    "            if j == i:\n",
    "                term = tensorproduct(term, (sigma_x - 1j * sigma_y) / 2)\n",
    "            else:\n",
    "                term = tensorproduct(term, identity)\n",
    "        L_list.append(term)\n",
    "    return np.array(L_list)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${A_a}^b = \\sum_{r,s,t}\\left(H_{rs}{N^b}_{st}M_{atr}-{N^b}_{rs}H_{st}M_{atr}\\right)$$\n",
    "$${B_a}^b= \\sum_{j, r,s,t,u}L_{jrs}{N^b}_{st}L_{jut}^* M_{aur}-\\frac{1}{2}L_{jsr}^* L_{jst} {N^b}_{tu} M_{aur} - \\frac{1}{2}{N^b}_{rs} L_{jts}^* L_{jtu} M_{aur}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_A(H, M, N):\n",
    "    term1 = ncon((H, N, M), ([1,2],[-2,2,3],[-1,3,1]))\n",
    "    term2 = ncon((N, H, M), ([-2,1,2],[2,3],[-1,3,1]))\n",
    "    return term1 - term2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_B(L, M, N): \n",
    "    term1 = ncon((L, N, np.conj(L), M), ([1,2,3],[-2,3,4],[1,5,4],[-1,5,2]))\n",
    "    term2 = ncon((np.conj(L), L, N, M), ([1,3,2],[1,3,4],[-2,4,5],[-1,5,2]))\n",
    "    term3 = ncon((N, np.conj(L), L, M), ([-2,2,3],[1,4,3],[1,4,5],[-1,5,2]))\n",
    "    return term1 - term2/2 - term3 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_list = np.linspace(0, 4, 17)\n",
    "\n",
    "\n",
    "def direct():\n",
    "    p_list = []\n",
    "    for g in g_list:\n",
    "        start_time = time.time()\n",
    "        H = gen_H(num_latt, coup_stren, g)\n",
    "        L = gen_L(num_latt)\n",
    "        A = gen_A(H, Mn, Ntn)\n",
    "        B = gen_B(L, Mn, Ntn)\n",
    "        C = (-1j * A + B).real\n",
    "        p = sp.linalg.null_space(C)\n",
    "        p /= np.sum(p)\n",
    "        p_list.append(p.flatten())\n",
    "        print(g, time.time() - start_time)\n",
    "    return p_list\n",
    "\n",
    "def gradient():\n",
    "    p_list = []\n",
    "    for g in g_list:\n",
    "        start_time = time.time()\n",
    "        initial_parameters = np.random.random(4 ** num_latt - 1)\n",
    "        H = gen_H(num_latt, coup_stren, g)\n",
    "        L = gen_L(num_latt)\n",
    "        A = gen_A(H, Mn, Ntn)\n",
    "        B = gen_B(L, Mn, Ntn)\n",
    "        C = (-1j * A + B).real\n",
    "        def loss(parameters):\n",
    "            prob = np.append(parameters, 0)\n",
    "            prob[-1] = 1 - np.sum(prob)\n",
    "            prob_dot = C @ prob\n",
    "            return np.linalg.norm(prob_dot)\n",
    "        res = optimize.minimize(loss, initial_parameters, options={'gtol':1e-12})\n",
    "        optimized_parameters = res.x\n",
    "        loss_value = res.fun\n",
    "        p = np.append(optimized_parameters, 0)\n",
    "        p[-1] = 1 - np.sum(p)\n",
    "        p_list.append(p)\n",
    "        print(g, loss_value, time.time() - start_time)\n",
    "    return p_list\n",
    "\n",
    "p_list = []\n",
    "if method == 'direct':\n",
    "    p_list = direct()\n",
    "elif method == 'gradient':\n",
    "    p_list = gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_list = []\n",
    "for p in p_list:\n",
    "    #print(p.shape)\n",
    "    #print(Ntn.shape)\n",
    "    rho = ncon((p, Ntn), ([1],[1,-1,-2]))\n",
    "    rho_list.append(rho)\n",
    "rho_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_big_sigma(sigma, num):\n",
    "    big_sigma = np.zeros((2**num, 2**num), dtype = 'complex128')\n",
    "    for i in range(num):\n",
    "        current_sigma = np.array([1])\n",
    "        for j in range(num):\n",
    "            if j == i:\n",
    "                current_sigma = tensorproduct(current_sigma, sigma)\n",
    "            else:\n",
    "                current_sigma = tensorproduct(current_sigma, identity)\n",
    "            #print(i, j, current_sigma)\n",
    "        big_sigma += current_sigma\n",
    "    big_sigma /= num\n",
    "    return big_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_big_sigma(sigma_z, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_sigma_x = gen_big_sigma(sigma_x, num_latt)\n",
    "big_sigma_y = gen_big_sigma(sigma_y, num_latt)\n",
    "big_sigma_z = gen_big_sigma(sigma_z, num_latt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_sigma_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_x_expect = list(map(lambda r: np.trace(r @ big_sigma_x), rho_list))\n",
    "sigma_y_expect = list(map(lambda r: np.trace(r @ big_sigma_y), rho_list))\n",
    "sigma_z_expect = list(map(lambda r: np.trace(r @ big_sigma_z), rho_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(g_list, sigma_x_expect)\n",
    "plt.xlabel(r'$g / \\gamma$')\n",
    "plt.ylabel(r'$\\langle\\sigma_x\\rangle$')\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(g_list, sigma_y_expect)\n",
    "plt.xlabel(r'$g / \\gamma$')\n",
    "plt.ylabel(r'$\\langle\\sigma_y\\rangle$')\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(g_list, sigma_z_expect)\n",
    "plt.xlabel(r'$g / \\gamma$')\n",
    "plt.ylabel(r'$\\langle\\sigma_z\\rangle$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_list2 = np.load('rho_list.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_list1 = np.array(rho_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(rho_list2-rho_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
